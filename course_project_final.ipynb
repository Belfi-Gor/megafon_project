{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import luigi\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score, learning_curve\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb, lightgbm as lgbm, catboost as catb\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
    "    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
    "    print('CONFUSION MATRIX\\n')\n",
    "    print(pd.crosstab(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gb(input_train, input_valid, input_need_predict, target_col, model_type, scale, random_state, scale_pos_weight, verbose=False):\n",
    "    import xgboost as xgb\n",
    "    import catboost as catb\n",
    "    import lightgbm as lgbm\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    if (verbose):\n",
    "        print(\"Включена отладка:\")\n",
    "        print(f\"    input_train.shape={input_train.shape}\")\n",
    "        if (type(input_valid) != bool): print(f\"    input_valid.shape={input_valid.shape}\")\n",
    "        if (type(input_need_predict) != bool): print(f\"    input_need_predict.shape={input_need_predict.shape}\")\n",
    "        print(f\"    target_col={target_col}\")\n",
    "        print(f\"    model_type={model_type}\")\n",
    "        print(f\"    scale={scale}\")\n",
    "        print(f\"    random_state={random_state}\")\n",
    "        print(f\"    scale_pos_weight={scale_pos_weight}\")\n",
    "        \n",
    "    train = copy.deepcopy(input_train)\n",
    "    valid = copy.deepcopy(input_valid)\n",
    "    need_predict = copy.deepcopy(input_need_predict)\n",
    "    \n",
    "    if (scale):\n",
    "        print(\"Масштабирую данные\")\n",
    "        scaler = StandardScaler()\n",
    "        train_scaler = scaler.fit_transform(train)\n",
    "        train = pd.DataFrame(train_scaler, columns=train.columns)\n",
    "        valid_scaler = scaler.fit_transform(valid)\n",
    "        valid = pd.DataFrame(valid_scaler, columns=valid.columns)\n",
    "    \n",
    "    print(\"====================================\")\n",
    "    print(f\"Тип модели: {model_type}\")\n",
    "    if (type(input_need_predict) != bool):  print(f\"Боевой запуск\")\n",
    "    \n",
    "    if (model_type==\"xgb\"):\n",
    "        model = xgb.XGBClassifier(random_state=random_state, scale_pos_weight=scale_pos_weight)\n",
    "    elif (model_type==\"catb\"):\n",
    "        model = catb.CatBoostClassifier(silent=True, random_state=random_state, scale_pos_weight=scale_pos_weight)\n",
    "    elif (model_type==\"lgbm\"):\n",
    "        model = lgbm.LGBMClassifier(random_state=random_state, n_jobs=-1, scale_pos_weight=scale_pos_weight)\n",
    "    elif (model_type==\"all\"):\n",
    "        \n",
    "        model_xgb = my_gb(input_train, input_valid, False, 'target', \"xgb\", False, 42, 16.29, True)\n",
    "        model_catb = my_gb(input_train, input_valid, False, 'target', \"catb\", False, 42, 16.29, True)\n",
    "        model_lgbm = my_gb(input_train, input_valid, False, 'target', \"lgbm\", False, 42, 16.29, True)\n",
    "        model_summary = [model_xgb, model_catb, model_lgbm]\n",
    "#         print(f\"возвращаю {model_summary[np.argmax(model_summary.T[0][0])]}\")\n",
    "        return model_summary[np.argmax(model_summary.T[0][0])]\n",
    "    else:\n",
    "        print(f\"Неправильный параметр model_type: {model_type}\")\n",
    "        return False\n",
    "    \n",
    "    train_target = train.pop(target_col) #Отделяю целевое значение\n",
    "    model.fit(train, train_target)\n",
    "    pred_train = model.predict(train)\n",
    "    if (type(valid) != bool):\n",
    "        print(f\"Произвожу валидацию\")\n",
    "        valid_target = valid.pop(target_col)\n",
    "        pred_valid = model.predict(valid)\n",
    "        print(get_classification_report(train_target, pred_train, valid_target, pred_valid))\n",
    "        model_f1_score = f1_score(valid_target, pred_valid, average='macro')\n",
    "        \n",
    "    \n",
    "    if (type(need_predict) != bool):\n",
    "        print(f\"Прогнозирую {target_col}\")\n",
    "        need_predict.pop(target_col)\n",
    "        return model.predict(need_predict)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    return [[model_f1_score], [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetTrainPrepare(luigi.Task):\n",
    "    \n",
    "        \n",
    "    def run(self):\n",
    "        data_train = pd.read_csv('data_train.csv', index_col='id')\n",
    "        data_train = data_train.drop('Unnamed: 0', axis=1)\n",
    "#         data_train.to_csv('train_processed.csv', index=True)\n",
    "        with self.output().open('w') as f:\n",
    "            data_train.to_csv(f, index=True)\n",
    "    \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(path='output_train.csv')\n",
    "\n",
    "        \n",
    "class DatasetTestPrepare(luigi.Task):\n",
    "    \n",
    "    def run(self):\n",
    "        data_test = pd.read_csv('data_test.csv', index_col='id')\n",
    "        data_test = data_test.drop('Unnamed: 0', axis=1)\n",
    "#         data_train.to_csv('test_processed.csv', index=True)\n",
    "        with self.output().open('w') as f:\n",
    "            data_test.to_csv(f, index=True)\n",
    "        \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(path='output_test.csv')\n",
    "    \n",
    "class DatasetFeaturesFilter(luigi.Task):\n",
    "\n",
    "    def requires(self):\n",
    "        return DatasetTrainPrepare()\n",
    "\n",
    "    def run(self):\n",
    "#         data_features = pd.read_csv('features.zip', compression='zip', sep='\\t', index_col='id')\n",
    "        data_features = pd.read_csv('features.csv', sep='\\t', index_col='id')\n",
    "        data_features = data_features.drop('Unnamed: 0', axis=1)\n",
    "        data_train=pd.read_csv('output_train.csv', index_col='id')\n",
    "        data_features = data_features.loc[data_train.index]\n",
    "        \n",
    "        with self.output().open('w') as f:\n",
    "            data_features.to_csv(f, index=True)\n",
    "    \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(path='output_features_filtered.csv')\n",
    "    \n",
    "class DatasetTrainTestConcat(luigi.Task):\n",
    "    \n",
    "    def requires(self):\n",
    "        return DatasetFeaturesFilter()\n",
    "#         DatasetTrainPrepare()\n",
    "        \n",
    "    def run(self):\n",
    "        data_train = pd.read_csv('output_train.csv', index_col='id') #подгружаю трейн\n",
    "        data_features = pd.read_csv('output_features_filtered.csv', index_col='id') #подгружаю параметры\n",
    "        #дополняю трейн параметрами\n",
    "        data_train = pd.merge(data_train, data_features, how=\"left\", left_index=True, right_index=True)\n",
    "        #отбрасываю записи где дата предложения < даты параметров\n",
    "        data_train = data_train.drop(data_train.loc[data_train.buy_time_x < data_train.buy_time_y].index)\n",
    "        #отбрасываю дубли\n",
    "        data_train = data_train.drop(data_train.loc[data_train.duplicated()].index)\n",
    "        data_train['buy_time'] = data_train['buy_time_x'] \n",
    "        data_train = data_train.drop(['buy_time_x', 'buy_time_y'], axis=1)\n",
    "#         temp_train['datetime'] = pd.to_datetime(temp_train['buy_time'].values, unit='s').date\n",
    "#         temp_train = temp_train.sort_values(by=['datetime'], ascending=True)\n",
    "\n",
    "#     from sklearn.model_selection import train_test_split\n",
    "#         RANDOM_STATE = 42\n",
    "\n",
    "        temp_train, temp_test = train_test_split(data_train, test_size=0.25, random_state=42)\n",
    "#         temp_test = temp_train.loc[test_idx].to_csv(\"output_ready_to_test.csv\")\n",
    "        temp_test.to_csv(\"output_ready_to_test.csv\")\n",
    "#         temp_tain = temp_train.loc[train_idx]\n",
    "\n",
    "        with self.output().open('w') as f:\n",
    "            temp_train.to_csv(f, index=True)\n",
    "            \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(path='output_ready_to_train.csv')\n",
    "    \n",
    "class ModelTrainCATBClassifier(luigi.Task):\n",
    "    def requires(self):\n",
    "        return DatasetTrainTestConcat()\n",
    "    \n",
    "    def run(self):\n",
    "        data_train = pd.read_csv('output_ready_to_train.csv', index_col='id')\n",
    "        \n",
    "        print(data_train.head())\n",
    "        \n",
    "        data_train.head()\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        RANDOM_STATE = 42\n",
    "\n",
    "        train_idx, test_idx = train_test_split(data_train.index, test_size=0.25, random_state=RANDOM_STATE)\n",
    "        \n",
    "        model = my_gb(data_train.loc[train_idx], data_train.loc[test_idx], False, 'target', \"catb\", False, RANDOM_STATE, 16.29, True)\n",
    "        \n",
    "        with open('model_catb.pkl', 'wb') as fid:\n",
    "            pickle.dump(model[1], fid)  \n",
    "    \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(path='model_catb.pkl')\n",
    "    \n",
    "class ModelTrainXGBClassifier(luigi.Task):\n",
    "    def requires(self):\n",
    "        return DatasetTrainTestConcat()\n",
    "    \n",
    "    def run(self):\n",
    "        data_train = pd.read_csv('output_ready_to_train.csv', index_col='id')\n",
    "        \n",
    "        print(data_train.head())\n",
    "        \n",
    "        data_train.head()\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        RANDOM_STATE = 42\n",
    "\n",
    "        train_idx, test_idx = train_test_split(data_train.index, test_size=0.25, random_state=RANDOM_STATE)\n",
    "        \n",
    "        model = my_gb(data_train.loc[train_idx], data_train.loc[test_idx], False, 'target', \"xgb\", False, RANDOM_STATE, 16.29, True)\n",
    "        \n",
    "        with open('model_xgb.pkl', 'wb') as fid:\n",
    "            pickle.dump(model[1], fid)  \n",
    "    \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(path='model_xgb.pkl')\n",
    "    \n",
    "\n",
    "    \n",
    "class ModelTrainLGBMClassifier(luigi.Task):\n",
    "    def requires(self):\n",
    "        return DatasetTrainTestConcat()\n",
    "    \n",
    "    def run(self):\n",
    "        data_train = pd.read_csv('output_ready_to_train.csv', index_col='id')\n",
    "        \n",
    "        print(data_train.head())\n",
    "        \n",
    "        data_train.head()\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        RANDOM_STATE = 42\n",
    "\n",
    "        train_idx, test_idx = train_test_split(data_train.index, test_size=0.25, random_state=RANDOM_STATE)\n",
    "        \n",
    "        model = my_gb(data_train.loc[train_idx], data_train.loc[test_idx], False, 'target', \"lgbm\", False, RANDOM_STATE, 16.29, True)\n",
    "        \n",
    "        with open('model_lgbm.pkl', 'wb') as fid:\n",
    "            pickle.dump(model[1], fid)  \n",
    "    \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(path='model_lgbm.pkl')\n",
    "    \n",
    "class CompareModels(luigi.Task):\n",
    "    \n",
    "    def requires(self):\n",
    "        return ModelTrainLGBMClassifier(), ModelTrainXGBClassifier(), ModelTrainCATBClassifier()\n",
    "    \n",
    "    def run(self):\n",
    "        data_test = pd.read_csv('output_ready_to_test.csv', index_col='id')\n",
    "        model = {}\n",
    "        predictions = {}\n",
    "        y_test = data_test['target']\n",
    "        X_test = data_test.drop('target', axis=1)\n",
    "        with open('model_xgb.pkl', 'rb') as fid:\n",
    "            model[0] = pickle.load(fid)\n",
    "        with open('model_catb.pkl', 'rb') as fid:\n",
    "            model[1] = pickle.load(fid)\n",
    "        with open('model_lgbm.pkl', 'rb') as fid:\n",
    "            model[2] = pickle.load(fid)\n",
    "\n",
    "        predictions[0] = model[0][0].predict(X_test)\n",
    "        predictions[1] = model[1][0].predict(X_test)\n",
    "        predictions[2] = model[2][0].predict(X_test)\n",
    "\n",
    "        f1_scores = []\n",
    "        f1_scores.append(f1_score(predictions[0], y_test, average='macro'))\n",
    "        f1_scores.append(f1_score(predictions[1], y_test, average='macro'))\n",
    "        f1_scores.append(f1_score(predictions[2], y_test, average='macro'))\n",
    "\n",
    "        with open('taki_best_model.pkl', 'wb') as fid:\n",
    "                    pickle.dump(model[np.argmax(f1_scores)][0], fid)\n",
    "        \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(path='taki_best_model.pkl')\n",
    "\n",
    "    \n",
    "class ModelFinalPrediction(luigi.Task):\n",
    "    \n",
    "    def requires(self):\n",
    "        return CompareModels()\n",
    "        \n",
    "    def run(self):\n",
    "        data_test = pd.read_csv('data_test.csv', index_col='id') #подгружаю test\n",
    "        data_test = data_test.drop('Unnamed: 0', axis=1)\n",
    "#         data_features_temp = pd.read_csv('features.zip', compression='zip', sep='\\t', index_col='id')\n",
    "        data_features_temp = pd.read_csv('features.csv', sep='\\t', index_col='id')\n",
    "\n",
    "\n",
    "        data_features = data_features_temp.loc[data_test.index]\n",
    "        data_features = data_features.drop('Unnamed: 0', axis=1)\n",
    "        data_features.sort_values(by=['buy_time'], inplace=True)\n",
    "        data_features = data_features.groupby(data_features.index).last()\n",
    "        X_test = pd.merge(data_test, data_features, how=\"left\", left_index=True, right_index=True)\n",
    "        X_test['buy_time'] = X_test['buy_time_x']\n",
    "        X_test = X_test.drop(['buy_time_x', 'buy_time_y'], axis=1)  \n",
    "        \n",
    "        with open('taki_best_model.pkl', 'rb') as fid:\n",
    "            best_model = pickle.load(fid)\n",
    "            \n",
    "        answers = best_model.predict(X_test)\n",
    "        data_test['target'] = answers\n",
    "#         data_test['id'] = data_test.index\n",
    "        \n",
    "        with self.output().open('w') as f:\n",
    "            data_test.to_csv(f, index=True)\n",
    "            \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(path='answers_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if ModelFinalPrediction() is complete\n",
      "DEBUG: Checking if CompareModels() is complete\n",
      "INFO: Informed scheduler that task   ModelFinalPrediction__99914b932b   has status   PENDING\n",
      "INFO: Informed scheduler that task   CompareModels__99914b932b   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 1\n",
      "INFO: [pid 3088] Worker Worker(salt=695487131, workers=1, host=DESKTOP-TTT8HHQ, username=admin, pid=3088) running   ModelFinalPrediction()\n",
      "INFO: [pid 3088] Worker Worker(salt=695487131, workers=1, host=DESKTOP-TTT8HHQ, username=admin, pid=3088) done      ModelFinalPrediction()\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   ModelFinalPrediction__99914b932b   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "INFO: Worker Worker(salt=695487131, workers=1, host=DESKTOP-TTT8HHQ, username=admin, pid=3088) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 2 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 CompareModels()\n",
      "* 1 ran successfully:\n",
      "    - 1 ModelFinalPrediction()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#     luigi.build([DatasetTrainPrepare()])\n",
    "#     luigi.build([DatasetTestPrepare()])\n",
    "#     luigi.build([ModelTrainCATBClassifier()])\n",
    "#     luigi.build([ModelTrainXGBClassifier()])\n",
    "    luigi.build([ModelFinalPrediction()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
